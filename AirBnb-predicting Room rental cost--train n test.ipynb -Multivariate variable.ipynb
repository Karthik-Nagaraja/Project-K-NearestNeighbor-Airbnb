{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 ways we can tweak the model to try to improve the accuracy (decrease the RMSE during validation):\n",
    "\n",
    "    increase the number of attributes the model uses to calculate similarity when ranking the closest neighbors\n",
    "    increase k, the number of nearby neighbors the model uses when computing the prediction\n",
    "\n",
    "In this mission, we'll focus on increasing the number of attributes the model uses. When selecting more attributes to use in the model, we need to watch out for columns that don't work well with the distance equation. This includes columns containing:\n",
    "\n",
    "    non-numerical values (e.g. city or state)\n",
    "        Euclidean distance equation expects numerical values\n",
    "    missing values\n",
    "        distance equation expects a value for each observation and attribute\n",
    "    non-ordinal values (e.g. latitude or longitude)\n",
    "        ranking by Euclidean distance doesn't make sense if all attributes aren't ordinal\n",
    "\n",
    "In the following code screen, we've read the dc_airbnb.csv dataset from the last mission into pandas and brought over the data cleaning changes we made. Let's first look at the first row's values to identify any columns containing non-numerical or non-ordinal values. In the next screen, we'll drop those columns and then look for missing values in each of the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3723 entries, 574 to 1061\n",
      "Data columns (total 19 columns):\n",
      "host_response_rate      3289 non-null object\n",
      "host_acceptance_rate    3109 non-null object\n",
      "host_listings_count     3723 non-null int64\n",
      "accommodates            3723 non-null int64\n",
      "room_type               3723 non-null object\n",
      "bedrooms                3702 non-null float64\n",
      "bathrooms               3696 non-null float64\n",
      "beds                    3712 non-null float64\n",
      "price                   3723 non-null float64\n",
      "cleaning_fee            2335 non-null object\n",
      "security_deposit        1426 non-null object\n",
      "minimum_nights          3723 non-null int64\n",
      "maximum_nights          3723 non-null int64\n",
      "number_of_reviews       3723 non-null int64\n",
      "latitude                3723 non-null float64\n",
      "longitude               3723 non-null float64\n",
      "city                    3723 non-null object\n",
      "zipcode                 3714 non-null object\n",
      "state                   3723 non-null object\n",
      "dtypes: float64(6), int64(5), object(8)\n",
      "memory usage: 581.7+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "dc_listings = pd.read_csv('dc_airbnb.csv')\n",
    "dc_listings = dc_listings.loc[np.random.permutation(len(dc_listings))]\n",
    "stripped_commas = dc_listings['price'].str.replace(',', '')\n",
    "stripped_dollars = stripped_commas.str.replace('$', '')\n",
    "dc_listings['price'] = stripped_dollars.astype('float')\n",
    "dc_listings.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Removing features\n",
    "\n",
    "The following columns contain non-numerical values:\n",
    "\n",
    "    room_type: e.g. Private room\n",
    "    city: e.g. Washington\n",
    "    state: e.g. DC\n",
    "\n",
    "while these columns contain numerical but non-ordinal values:\n",
    "\n",
    "    latitude: e.g. 38.913458\n",
    "    longitude: e.g. -77.031\n",
    "    zipcode: e.g. 20009\n",
    "\n",
    "Geographic values like these aren't ordinal, because a smaller numerical value doesn't directly correspond to a smaller value in a meaningful way. For example, the zip code 20009 isn't smaller or larger than the zip code 75023 and instead both are unique, identifier values. Latitude and longitude value pairs describe a point on a geographic coordinate system and different equations are used in those cases (e.g. haversine).\n",
    "\n",
    "While we could convert the host_response_rate and host_acceptance_rate columns to be numerical (right now they're object data types and contain the % sign), these columns describe the host and not the living space itself. Since a host could have many living spaces and we don't have enough information to uniquely group living spaces to the hosts themselves, let's avoid using any columns that don't directly describe the living space or the listing itself:\n",
    "\n",
    "    host_response_rate\n",
    "    host_acceptance_rate\n",
    "    host_listings_count\n",
    "\n",
    "Let's remove these 9 columns from the Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates            0\n",
      "bedrooms               21\n",
      "bathrooms              27\n",
      "beds                   11\n",
      "price                   0\n",
      "cleaning_fee         1388\n",
      "security_deposit     2297\n",
      "minimum_nights          0\n",
      "maximum_nights          0\n",
      "number_of_reviews       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels=['room_type','city','state','latitude','longitude','zipcode','host_response_rate','host_acceptance_rate','host_listings_count']\n",
    "dc_listings=dc_listings.drop(labels,axis=1)\n",
    "print(dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling missing values\n",
    "\n",
    "Of the remaining columns, 3 columns have a few missing values (less than 1% of the total number of rows):\n",
    "\n",
    "    bedrooms\n",
    "    bathrooms\n",
    "    beds\n",
    "\n",
    "Since the number of rows containing missing values for one of these 3 columns is low, we can select and remove those rows without losing much information. There are also 2 columns have a large number of missing values:\n",
    "\n",
    "    cleaning_fee - 37.3% of the rows\n",
    "    security_deposit - 61.7% of the rows\n",
    "\n",
    "and we can't handle these easily. We can't just remove the rows containing missing values for these 2 columns because we'd miss out on the majority of the observations in the dataset. Instead, let's remove these 2 columns entirely from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accommodates         0\n",
      "bedrooms             0\n",
      "bathrooms            0\n",
      "beds                 0\n",
      "price                0\n",
      "minimum_nights       0\n",
      "maximum_nights       0\n",
      "number_of_reviews    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dc_listings=dc_listings.drop(['cleaning_fee','security_deposit'],axis=1)\n",
    "dc_listings=dc_listings.dropna(subset=['bedrooms', 'bathrooms','beds'],axis=0)\n",
    "print(dc_listings.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize columns\n",
    "\n",
    "Here's how the dc_listings Dataframe looks like after all the changes we made:\n",
    "accommodates \tbedrooms \tbathrooms \tbeds \tprice \tminimum_nights \tmaximum_nights \tnumber_of_reviews\n",
    "2 \t1.0 \t1.0 \t1.0 \t125.0 \t1 \t4 \t149\n",
    "2 \t1.0 \t1.5 \t1.0 \t85.0 \t1 \t30 \t49\n",
    "1 \t1.0 \t0.5 \t1.0 \t50.0 \t1 \t1125 \t1\n",
    "2 \t1.0 \t1.0 \t1.0 \t209.0 \t4 \t730 \t2\n",
    "12 \t5.0 \t2.0 \t5.0 \t215.0 \t2 \t1825 \t34\n",
    "\n",
    "You may have noticed that while the accommodates, bedrooms, bathrooms, beds, and minimum_nights columns hover between 0 and 12 (at least in the first few rows), the values in the maximum_nights and number_of_reviews columns span much larger ranges. For example, the maximum_nights column has values as low as 4 and high as 1825, in the first few rows itself. If we use these 2 columns as part of a k-nearest neighbors model, these attributes could end up having an outsized effect on the distance calculations because of the largeness of the values.\n",
    "\n",
    "For example, 2 living spaces could be identical across every attribute but be vastly different just on the maximum_nights column. If one listing had a maximum_nights value of 1825 and the other a maximum_nights value of 4, because of the way Euclidean distance is calculated, these listings would be considered very far apart because of the outsized effect the largeness of the values had on the overall Euclidean distance. To prevent any single column from having too much of an impact on the distance, we can normalize all of the columns to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "Normalizing the values in each columns to the standard normal distribution (mean of 0, standard deviation of 1) preserves the distribution of the values in each column while aligning the scales. To normalize the values in a column to the standard normal distribution, you need to:\n",
    "\n",
    "    from each value, subtract the mean of the column\n",
    "    divide each value by the standard deviation of the column\n",
    "\n",
    "Here's the mathematical formula describing the transformation that needs to be applied for all values in a column:\n",
    "\n",
    ".\n",
    "\n",
    "where\n",
    "is a value in a specific column, is the mean of all the values in the column, and\n",
    "\n",
    "is the standard deviation of all the values in the column. Here's what the corresponding code, using pandas, looks like:\n",
    "\n",
    "# Subtract each value in the column by the mean.\n",
    "\n",
    "first_transform = dc_listings['maximum_nights'] - dc_listings['maximum_nights'].mean()\n",
    "\n",
    "# Divide each value in the column by the standard deviation.\n",
    "\n",
    "normalized_col = first_transform / first_transform.std()\n",
    "\n",
    "To apply this transformation across all of the columns in a Dataframe, you can use the corresponding Dataframe methods mean() and std():\n",
    "\n",
    "normalized_listings = (dc_listings - dc_listings.mean()) / (dc_listings.std())\n",
    "\n",
    "These methods were written with mass column transformation in mind and when you call mean() or std(), the appropriate column means and column standard deviations are used for each value in the Dataframe. Let's now normalize all of the feature columns in dc_listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>-0.596544</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>-0.439151</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016604</td>\n",
       "      <td>4.579650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>-0.596544</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>0.412923</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016603</td>\n",
       "      <td>1.159275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>-1.095499</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>-1.291226</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-0.341375</td>\n",
       "      <td>-0.016573</td>\n",
       "      <td>-0.482505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>-0.596544</td>\n",
       "      <td>-0.249467</td>\n",
       "      <td>-0.439151</td>\n",
       "      <td>-0.546858</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.487635</td>\n",
       "      <td>-0.016584</td>\n",
       "      <td>-0.448301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>4.393004</td>\n",
       "      <td>4.507903</td>\n",
       "      <td>1.264998</td>\n",
       "      <td>2.829956</td>\n",
       "      <td>215.0</td>\n",
       "      <td>-0.065038</td>\n",
       "      <td>-0.016553</td>\n",
       "      <td>0.646219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      accommodates  bedrooms  bathrooms      beds  price  minimum_nights  \\\n",
       "574      -0.596544 -0.249467  -0.439151 -0.546858  125.0       -0.341375   \n",
       "1593     -0.596544 -0.249467   0.412923 -0.546858   85.0       -0.341375   \n",
       "3091     -1.095499 -0.249467  -1.291226 -0.546858   50.0       -0.341375   \n",
       "420      -0.596544 -0.249467  -0.439151 -0.546858  209.0        0.487635   \n",
       "808       4.393004  4.507903   1.264998  2.829956  215.0       -0.065038   \n",
       "\n",
       "      maximum_nights  number_of_reviews  \n",
       "574        -0.016604           4.579650  \n",
       "1593       -0.016603           1.159275  \n",
       "3091       -0.016573          -0.482505  \n",
       "420        -0.016584          -0.448301  \n",
       "808        -0.016553           0.646219  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "normalized_listings = (dc_listings - dc_listings.mean())/(dc_listings.std())\n",
    "normalized_listings['price'] = dc_listings['price']\n",
    "normalized_listings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean distance for multivariate case\n",
    "\n",
    "In the last mission, we trained 2 univariate k-nearest neighbors models. The first one used the accommodates attribute while the second one used the bathrooms attribute. Let's now train a model that uses both attributes when determining how similar 2 living spaces are. Let's refer to the Euclidean distance equation again to see what the distance calculation using 2 attributes would look like:\n",
    "\n",
    "Since we're using 2 attributes, the distance calculation would look like:\n",
    "\n",
    "To find the distance between 2 living spaces, we need to calculate the squared difference between both accommodates values, the squared difference between both bathrooms values, add them together, and then take the square root of the resulting sum. Here's what the Euclidean distance between the first 2 rows in normalized_listings looks like:\n",
    "\n",
    "Imgur\n",
    "\n",
    "So far, we've been calculating Euclidean distance ourselves by writing the logic for the equation ourselves. We can instead use the distance.euclidean() function from scipy.spatial, which takes in 2 vectors as the parameters and calculates the Euclidean distance between them. The euclidean() function expects:\n",
    "\n",
    "    both of the vectors to be represented using a list-like object (Python list, NumPy array, or pandas Series)\n",
    "    both of the vectors must be 1-dimensional and have the same number of elements\n",
    "\n",
    "Here's a simple example:\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "first_listing = [-0.596544, -0.439151]\n",
    "\n",
    "second_listing = [-0.596544, 0.412923]\n",
    "\n",
    "dist = distance.euclidean(first_listing, second_listing)\n",
    "\n",
    "Let's use the euclidean() function to calculate the Euclidean distance between 2 rows in our dataset to practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.27254312467\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "first_listing = normalized_listings.iloc[0][['accommodates', 'bathrooms']]\n",
    "fifth_listing = normalized_listings.iloc[4][['accommodates', 'bathrooms']]\n",
    "first_fifth_distance = distance.euclidean(first_listing, fifth_listing)\n",
    "print(first_fifth_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Introducing KNeighborRegressor classifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "knn=KNeighborsRegressor(n_neighbors=5,algorithm='brute')\n",
    "train_feature=train_df.loc[:,['accommodates','bathrooms']]\n",
    "train_target=train_df['price']\n",
    "test_feature=test_df.loc[:,['accommodates','bathrooms']]\n",
    "test_target =  test_df['price']                        \n",
    "knn.fit(train_feature,train_target)\n",
    "predictions=knn.predict(test_feature)                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15184.425165\n",
      "123.225099574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kknagara\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "test_df['prediction_price'] = predictions\n",
    "two_features_mse = mean_squared_error(test_df['price'],test_df['prediction_price'])\n",
    "print(two_features_mse)\n",
    "import numpy as np\n",
    "two_features_rmse = np.sqrt(two_features_mse)\n",
    "print(two_features_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14044.0656655\n",
      "118.507660788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kknagara\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "train_df = normalized_listings.iloc[0:2792]\n",
    "test_df = normalized_listings.iloc[2792:]\n",
    "knn=KNeighborsRegressor(n_neighbors=5,algorithm='brute')\n",
    "train_feature=train_df.loc[:,['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']]\n",
    "train_target=train_df['price']\n",
    "test_feature=test_df.loc[:,['accommodates', 'bedrooms', 'bathrooms', 'number_of_reviews']]\n",
    "test_target =  test_df['price']                        \n",
    "knn.fit(train_feature,train_target)\n",
    "predictions=knn.predict(test_feature)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "test_df['prediction_price'] = predictions\n",
    "four_features_mse = mean_squared_error(test_df['price'],test_df['prediction_price'])\n",
    "print(four_features_mse)\n",
    "import numpy as np\n",
    "four_features_rmse = np.sqrt(four_features_mse)\n",
    "print(four_features_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15392.6253925\n",
      "124.067019761\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5, algorithm='brute')\n",
    "\n",
    "features = train_df.columns.tolist()\n",
    "features.remove('price')\n",
    "\n",
    "knn.fit(train_df[features], train_df['price'])\n",
    "all_features_predictions = knn.predict(test_df[features])\n",
    "all_features_mse = mean_squared_error(test_df['price'], all_features_predictions)\n",
    "all_features_rmse = np.sqrt(all_features_mse )\n",
    "print(all_features_mse)\n",
    "print(all_features_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps\n",
    "\n",
    "Interestingly enough, the RMSE value actually increased to 125.1 when we used all of the features available to us. This means that selecting the right features is important and that using more features doesn't automatically improve prediction accuracy. We should re-phrase the lever we mentioned earlier from:\n",
    "\n",
    "    increase the number of attributes the model uses to calculate similarity when ranking the closest neighbors\n",
    "\n",
    "to:\n",
    "\n",
    "    select the relevant attributes the model uses to calculate similarity when ranking the closest neighbors\n",
    "\n",
    "The process of selecting features to use in a model is known as feature selection.\n",
    "\n",
    "In this mission, we prepared the data to be able to use more features, trained a few models using multiple features, and evaluates the different performance tradeoffs. We explored how using more features doesn't always improve the accuracy of a k-nearest neighbors model. In the next mission, we'll explore another knob for tuning k-nearest neighbor models -- the k value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice the workflow\n",
    "\n",
    "You may have noticed that the general workflow for finding the best model is:\n",
    "\n",
    "    select relevant features to use for predicting the target column.\n",
    "    use grid search to find the optimal hyperparameter value for the selected features.\n",
    "    evaluate the model's accuracy and repeat the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: 15184.425164960181}\n",
      "{5: 13281.215108077358}\n"
     ]
    }
   ],
   "source": [
    "two_features = ['accommodates', 'bathrooms']\n",
    "three_features = ['accommodates', 'bathrooms', 'bedrooms']\n",
    "hyper_params = [x for x in range(1,21)]\n",
    "# Append the first model's MSE values to this list.\n",
    "two_mse_values = list()\n",
    "# Append the second model's MSE values to this list.\n",
    "three_mse_values = list()\n",
    "two_hyp_mse = dict()\n",
    "three_hyp_mse = dict()\n",
    "\n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[two_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[two_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    two_mse_values.append(mse)\n",
    "two_lowest_mse = two_mse_values[0]      # Assume first value is lowest mse\n",
    "two_lowest_k = 1                        #assume k=1 is best \n",
    "for k,mse in enumerate(two_mse_values):\n",
    "    if mse < two_lowest_mse:\n",
    "        two_lowest_mse = mse     \n",
    "        two_lowest_k = k + 1\n",
    "    \n",
    "for hp in hyper_params:\n",
    "    knn = KNeighborsRegressor(n_neighbors=hp, algorithm='brute')\n",
    "    knn.fit(train_df[three_features], train_df['price'])\n",
    "    predictions = knn.predict(test_df[three_features])\n",
    "    mse = mean_squared_error(test_df['price'], predictions)\n",
    "    three_mse_values.append(mse)\n",
    "three_lowest_mse = three_mse_values[0]\n",
    "three_lowest_k = 1\n",
    "\n",
    "for k,mse in enumerate(three_mse_values):\n",
    "    if mse < three_lowest_mse:\n",
    "        three_lowest_mse = mse\n",
    "        three_lowest_k = k + 1\n",
    "\n",
    "two_hyp_mse[two_lowest_k] = two_lowest_mse\n",
    "three_hyp_mse[three_lowest_k] = three_lowest_mse\n",
    "\n",
    "print(two_hyp_mse)\n",
    "print(three_hyp_mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model, which used the accommodates and bathrooms columns, was able to achieve an MSE value of approximately 14790. The second model, which added the bedrooms column, was ble to achieve an MSE value of approximately 13522.9, which is even lower than the lowest MSE value we achieved using the best model from the last mission (which used the accommodates, bedrooms, bathrooms, and number_of_reviews columns. Hopefully this demonstrates that using just one lever to find the best model isn't enough and you really want to use both levers in conjunction."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
